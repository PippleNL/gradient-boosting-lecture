{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipple Lecture 5: Gradient Boosting met XGBoost\n",
    "\n",
    "### Case\n",
    "Omdat Bart bijna jarig is, is Pippi op zoek naar een geschikt cadeau voor hem. \n",
    "Pippi weet dat Bart van een biertje houdt en heeft dit jaar bij verschillende bieren bijgehouden hoe Bart hierop reageert.\n",
    "Die reactie heeft Pippi getransformeerd tot een rating van 0 tot 10.\n",
    "\n",
    "Om te kijken welk nieuw biertje het beste past bij Bart zijn smaak, wil Pippi een model maken om deze score te voorspellen op basis van verschillende eigenschappen van bieren. Hiervoor wil Pippi natuurlijk het beste model hebben, om het beste model te krijgen wil Pippi gebruik maken van de huidige Gradient Boosting en met name het package XGBoost. Het beste model zal gebaseerd wordt gemeten op basis van de Mean Absolute Error (MAE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importeren van packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gebruiken onderstaande packages. Mocht je deze nog niet hebben, dan zijn deze te downloaden via:\n",
    "\n",
    "- pip install xgboost\n",
    "- pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlezen van data\n",
    "We gebruiken de volgende datasets:\n",
    "- **train.csv** om te trainen\n",
    "- **valid.csv** om te checken hoe goed ons model werkt\n",
    "- **test.csv** om de definitieve voorspellingen te maken\n",
    "\n",
    "We hebben de volgende eigenschappen van de verschillende bieren:\n",
    "- **calorien**: hoeveel calorien zitten er in het bier?\n",
    "- **dichtheid**: de dichtheid van het bier?\n",
    "- **is_belgisch**: of het bier belgisch is?\n",
    "- **is_speciaal**: of het een speciaal bier is of een gewoon bier?\n",
    "- **pct_alcohol**: wat is het percentage alcohol in het bier?\n",
    "- **pct_eiwitten**: wat is het percentage eiwitten in het bier?\n",
    "- **pct_gist**: wat is het percentage gist in het bier?\n",
    "- **pct_hop**: wat is het percentage hop in het bier?\n",
    "- **recensie**: wat is de gemiddelde recensie van het publiek?\n",
    "- **suiker**: hoeveel suiker zit er in het bier?\n",
    "- **water_kw**: wat is de water kwaliteit van het bier?\n",
    "- **zuur**: hoe zuur is het bier?\n",
    "\n",
    "Daarnaast is er voor elk bier een **beoordeling** van Bart op een schaal van 0-10. Dit is de waarde die je gaat voorspellen. Aan de hand van deze data willen we een model maken die inschat hoe Bart andere bieren beoordeelt, zodat het beste bier voor zijn verjaardag gekozen kan worden. De data is zover als mogelijk als geprepocessed, zodat hier geen tijd meer aan gespendeerd hoeft te worden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training features en labels\n",
    "url_train = 'https://raw.githubusercontent.com/PippleNL/gradient-boosting-lecture/master/data/train.csv'\n",
    "train = pd.read_csv(url_train)\n",
    "train_X = train.iloc[:,:-1].copy()\n",
    "train_y = train.iloc[:,-1:].copy()\n",
    "\n",
    "# Validatie features en labels\n",
    "url_valid = 'https://raw.githubusercontent.com/PippleNL/gradient-boosting-lecture/master/data/valid.csv'\n",
    "valid = pd.read_csv(url_valid)\n",
    "valid_X = valid.iloc[:,:-1].copy()\n",
    "valid_y = valid.iloc[:,-1:].copy()\n",
    "\n",
    "# Test features en labels\n",
    "url_test_X = 'https://raw.githubusercontent.com/PippleNL/gradient-boosting-lecture/master/data/test_X.csv'\n",
    "test_X = pd.read_csv(url_test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De XGBoost data structure\n",
    "XGBoost maakt gebruik van een speciale data structure, waardoor XGBoost efficienter en effectiever kan werken. Mede hieraan dankt XGBoost zijn hoge performance.De representatie van XGBoost heet een DMatrix. In onderstaande code wordt de data omgezet naar deze representatie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=train_X.values, label=train_y.values, feature_names=train_X.columns)\n",
    "dvalid = xgb.DMatrix(data=valid_X.values, label=valid_y.values, feature_names=valid_X.columns)\n",
    "dtest = xgb.DMatrix(data=test_X.values, feature_names=test_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j76CP9t3evRX"
   },
   "source": [
    "### Een XGBoost model\n",
    "\n",
    "XGBoost heeft verscheidene parameters die getuned kunnen worden, zodat het model beter presteert.\n",
    "De volgende parameters kunnen getuned worden:\n",
    "- **eta** staat voor hoeveel elke decision tree bijdraagt aan de uiteindelijke voorspelling [default=0.3]\n",
    "- **gamm** is de minimale toegevoegde waarde van een nieuwe split [default=0]\n",
    "- **max_depth**\tis de maximale diepte van elke decision tree [default=6]\n",
    "- ***subsample** is de ratio van random training samples waarop elke decision tree wordt getraind [default=1.0]\n",
    "- **colsample_bytree** en **colsample_bylevel** geven aan welke ratios van de kolommen worden gebruikt per tree en per level [default=1.0]\n",
    "- **objective** is het type loss functie die we minimalizeren, bijv. binary:logistic, multi:softmax, multi:softprob [default=reg:linear]\n",
    "- **eval_metric** is de metric waarmee we evalueren hoe goed onze voorspellingen zijn op de validatie data [default according to objective]\n",
    "- **seed** staat voor welke random seed we gebruiken [default=0]\n",
    "- **num_round** geeft aan hoeveel decision trees we trainen\n",
    "\n",
    "Als voorbeeld geven we een simpel model, waarbij we enkele parameters kiezen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiseren van de parameters\n",
    "# Deze kun je allemaal aanpassen\n",
    "param = {'eta':0.5, \n",
    "         'max_depth':3, \n",
    "         'min_child_weight':1,\n",
    "         'gamma':0,\n",
    "         'subsample':1.0,\n",
    "         'colsample_bytree':1.0,\n",
    "         'colsample_bylevel':1.0,\n",
    "         'silent':1, \n",
    "         'objective':'reg:linear', \n",
    "         'eval_metric':'mae',\n",
    "         'seed': 42}\n",
    "\n",
    "num_round = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 641,
     "status": "ok",
     "timestamp": 1557919864061,
     "user": {
      "displayName": "Ruud Mullers",
      "photoUrl": "",
      "userId": "14904625597502918521"
     },
     "user_tz": -120
    },
    "id": "1nvpRLGbeu8y",
    "outputId": "49e030a0-2382-4426-d8cf-cab82d484bbc"
   },
   "outputs": [],
   "source": [
    "# Het model wordt getraind, gegeven de parameters\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "\n",
    "# Maak voorspellingen op training en validatie data\n",
    "y_true_train = train_y.values\n",
    "y_pred_train = bst.predict(dtrain)\n",
    "y_true_valid = valid_y.values\n",
    "y_pred_valid = bst.predict(dvalid)\n",
    "\n",
    "# Bereken de MAE score\n",
    "train_mae = mean_absolute_error(y_true_train, y_pred_train)\n",
    "valid_mae = mean_absolute_error(y_true_valid, y_pred_valid)\n",
    "print(\"Train MAE: {}\".format(round(train_mae, 5)))\n",
    "print(\"Valid MAE: {}\".format(round(valid_mae, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk6-gzVbsCZP"
   },
   "source": [
    "### Verbeteringen\n",
    "\n",
    "In het huidige model hebben we enkele parameters gekozen, maar hier is niet voldoende over nagedacht.\n",
    "Daarnaast hebben we dataset opgesplitst in een train en validatie set. Echter is het ook mogelijk om cross validation te doen binnen XGBoost, waardoor het model mogelijk verbeterd kan worden.\n",
    "\n",
    "Enkele tips zijn dus:\n",
    "- Maak gebruik van cross-validation\n",
    "- Verander de hyper parameters gegeven in bovenstaand stuk (misschien kun deze zelfs optimaliseren)\n",
    "- Check of het model niet resulteert in overfitting\n",
    "- maak gebruik van een Tree based model of een Lineair model\n",
    "\n",
    "### Cross validation\n",
    "In dit stuk wordt uitgelegd hoe gewerkt kan worden met [cross-validation](https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/). Om gebruik te maken van cross-validation dien je [XGBoost.cv()](https://rdrr.io/cran/xgboost/man/xgb.cv.html)\n",
    "te gebruiken. Hiervoor kan je de training en validatie data weer samenvoegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voeg train en valid data samen\n",
    "combi_X = pd.concat([train_X, valid_X], ignore_index=True)\n",
    "combi_y = pd.concat([train_y, valid_y], ignore_index=True)\n",
    "\n",
    "# Maak een DMatrix aan\n",
    "dcombi = xgb.DMatrix(data=combi_X.values, label=combi_y.values, feature_names=combi_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1557919854398,
     "user": {
      "displayName": "Ruud Mullers",
      "photoUrl": "",
      "userId": "14904625597502918521"
     },
     "user_tz": -120
    },
    "id": "9eEyktJpuupE",
    "outputId": "a082e04e-1c7a-44df-8e38-22344ffec5e4"
   },
   "outputs": [],
   "source": [
    "# Gebruik CV om overfitting te voorkomen\n",
    "param = {'eta':0.5, \n",
    "         'max_depth':3, \n",
    "         'min_child_weight':1,\n",
    "         'gamma':0,\n",
    "         'subsample':1.0,\n",
    "         'colsample_bytree':1.0,\n",
    "         'colsample_bylevel':1.0,\n",
    "         'silent':1, \n",
    "         'objective':'reg:linear', \n",
    "         'eval_metric':'mae',\n",
    "         'seed': 42}\n",
    "\n",
    "num_round = 5\n",
    "\n",
    "cv_results = xgb.cv(param, dcombi, \n",
    "                    num_boost_round=num_round,\n",
    "                    nfold=5, \n",
    "                    metrics={'mae'}, \n",
    "                    early_stopping_rounds=10)\n",
    "\n",
    "cv_results.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning met Grid Search\n",
    "We kunnen ook automatisch zoeken naar de optimale parameters voor ons model. Hiervoor definiÃ«ren we per parameter een range aan mogelijkheden. Daarna probeert de grid search alle mogelijke combinaties uit. Let op: als je veel mogelijkheden invoert per parameter kan de grid search lang duren! Probeer daarom eerst handmatig gevoel te krijgen voor welke parameters goed werken, zodat je ze daarna kan fine tunen met de grid search. Let op: de waarden van MAE die uit de grid search komen zijn negatief. Dit is omdat de sklearn API de metric altijd probeert te maximaliseren. Door de absolute waardes te nemen krijg je de echte MAE. Hoe dichter bij de 0, des te beter je model voorspelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We timen deze cel om een indicatie te geven van hoe lang de grid search duurt\n",
    "start = time.time()\n",
    "\n",
    "# Definieer hier je parameters\n",
    "# Voeg vooral meer opties toe\n",
    "cv_params = {'eta':[0.3, 0.5], \n",
    "             'n_estimators': [10, 20],\n",
    "             'max_depth':[6, 10],\n",
    "             'subsample':[0.8, 1.0],\n",
    "             'colsample_bytree':[0.8, 1.0],\n",
    "             'colsample_bylevel':[0.8, 1.0]}\n",
    "\n",
    "# Deze parameters hoef je niet aan te passen\n",
    "ind_params = {'seed':42, \n",
    "              'objective':'reg:linear',\n",
    "              'eval_metric':'mae',\n",
    "              'silent':1}\n",
    "\n",
    "# Initialiseer de grid search\n",
    "optimized_bst = GridSearchCV(xgb.XGBRegressor(**ind_params), \n",
    "                             cv_params, \n",
    "                             scoring = 'neg_mean_absolute_error', \n",
    "                             cv = 5, \n",
    "                             n_jobs = -1) \n",
    "optimized_bst.fit(valid_X, valid_y)\n",
    "\n",
    "end = time.time()\n",
    "print('Grid search voltooid in {} seconden'.format(round(end - start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laat de beste combinatie van parameters zien\n",
    "optimized_bst.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meerdere voorspellingen combineren\n",
    "Met de onderstaande cel kun je meerdere voorspellingen combineren. Momenteel wordt de unweighted average berekend. Je kunt zelf weights toevoegen mocht je dat willen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecteer de lijsten met voorspellingen\n",
    "preds_a = [1, 2, 3]\n",
    "preds_b = [4, 5, 6]\n",
    "preds_c = [7, 8, 9]\n",
    "\n",
    "# Bereken het gemiddelde van de lijsten\n",
    "combi_lists = np.array([preds_a,\n",
    "                        preds_b,\n",
    "                        preds_c])\n",
    "\n",
    "combi_preds = list(np.average(combi_lists, axis=0))\n",
    "\n",
    "combi_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voorspellingen maken op de test set\n",
    "Met de onderstaande cel kun je voorspellingen maken op de test set data. Deze worden opgeslagen als .csv bestand als '/data/preds-naam-van-team.csv'. Verander 'naam-van-team' naar jullie team naam en stuur het bestand naar gijs@pipple.nl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maak nieuwe voorspellingen\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# Voer hier de naam van je team in\n",
    "naam = 'naam-van-team'\n",
    "\n",
    "# Sla output op als .csv\n",
    "path = 'output-{}.csv'.format(naam)\n",
    "df = pd.DataFrame({'output': preds})\n",
    "df.to_csv(path, sep=',',index=False)\n",
    "\n",
    "from google.colab import files\n",
    "files.download(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
